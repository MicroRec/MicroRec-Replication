{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util, models\n",
    "from sklearn.feature_extraction import _stop_words as stop_words\n",
    "from tqdm.notebook import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import torch\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_enc_weights = './models/bienc-exp7/'\n",
    "cr_enc_weights = './models/crenc-exp7/'\n",
    "data_folder = 'generated5'\n",
    "top_k = 50\n",
    "use_base = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/20231004_data.xlsx', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "  tokenized_doc = []\n",
    "  for token in text.lower().split():\n",
    "    token = token.strip(string.punctuation)\n",
    "\n",
    "    if len(token) > 0 and token not in english_stopwords:\n",
    "      tokenized_doc.append(token)\n",
    "      \n",
    "  return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_base:\n",
    "    word_embedding_model = models.Transformer('distilroberta-base', max_seq_length=350)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    cr_encoder = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6')\n",
    "else:\n",
    "    bi_encoder = SentenceTransformer(bi_enc_weights)\n",
    "    cr_encoder = CrossEncoder(cr_enc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{data_folder}/test_passage.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open(f'./data/{data_folder}/test_corpus.json', 'r') as f:\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "val_query_answer = {}\n",
    "for idx, rel in val_passage.items():\n",
    "    query = val_corpus[idx]\n",
    "    pos = rel[0]\n",
    "    answers = [val_corpus[str(p)] for p in pos]\n",
    "    val_query_answer[idx] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def shorten(text):\n",
    "    tmp = text.split()[:512]\n",
    "    return ' '.join(tmp)\n",
    "\n",
    "val_text = list(val_corpus.values())\n",
    "\n",
    "\n",
    "with open(\"embeddings_GPT.json\", \"r\") as jsonfile:\n",
    "    embeddings_dict = json.load(jsonfile)\n",
    "\n",
    "val_emb_tensors = []\n",
    "\n",
    "\n",
    "title_to_id = dict(zip(df['Question Title'], df.index))\n",
    "\n",
    "# Convert the embeddings into tensors\n",
    "for text in val_text:\n",
    "    # Retrieve the ID for the given text\n",
    "    text_id = title_to_id[text]\n",
    "    embedding = embeddings_dict.get(str(text_id))  \n",
    "    if embedding:  \n",
    "        val_emb_tensors.append(torch.tensor(embedding))\n",
    "\n",
    "\n",
    "val_emb = torch.stack(val_emb_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tokenized_corpus = []\n",
    "for idx, passage in tqdm(val_corpus.items()):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bm25(query, answer, top_k=50):\n",
    "    # Convert answer to set for faster lookup\n",
    "    answer_set = set(answer)\n",
    "    \n",
    "    # Get bm25 scores for the query\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    \n",
    "    # Check if we have enough scores\n",
    "    if len(bm25_scores) < top_k:\n",
    "        raise ValueError(\"Not enough BM25 scores for top_k.\")\n",
    "    \n",
    "    # Retrieve the top-k indices based on bm25_scores\n",
    "    top_n = np.argpartition(bm25_scores, -top_k)[-top_k:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    bm25_counter = -1\n",
    "    bm25_map = 0\n",
    "    tmp_hits = 0\n",
    "    \n",
    "    # Iterate over top-k hits\n",
    "    for idx, hit in enumerate(bm25_hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer_set:\n",
    "            if bm25_counter == -1:\n",
    "                bm25_counter = idx + 1\n",
    "\n",
    "            tmp_hits += 1\n",
    "            bm25_map += tmp_hits / (idx + 1)\n",
    "            answer_set.remove(candidate)\n",
    "\n",
    "    bm25_map /= len(answer)\n",
    "    bm25_mrr = 1 / bm25_counter if bm25_counter != -1 else 0.0\n",
    "\n",
    "    return bm25_map, bm25_mrr\n",
    "\n",
    "def compute_cosine_similarity(query_embedding, corpus_embeddings):\n",
    "    # Normalize embeddings\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, keepdim=True)\n",
    "        query_embedding = query_embedding.unsqueeze(0)  # Add an additional dimension\n",
    "    else:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, dim=1, keepdim=True)\n",
    "    \n",
    "    corpus_embeddings = corpus_embeddings / torch.norm(corpus_embeddings, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_similarities = torch.mm(query_embedding, corpus_embeddings.transpose(0, 1))\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass_rerank(query, precomputed_embedding=None, val_embeddings=None, top_k=50):\n",
    "    \n",
    "    if precomputed_embedding is None:\n",
    "        q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    else:\n",
    "        q_emb = precomputed_embedding\n",
    "\n",
    "    # Ensure the query embedding is 2-dimensional\n",
    "    if len(q_emb.shape) == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "\n",
    "    if val_embeddings is None:\n",
    "        raise ValueError(\"No embeddings provided for the validation set.\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    if val_embeddings.shape[1] != q_emb.shape[1]:\n",
    "        val_embeddings = val_embeddings.transpose(0, 1)\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(q_emb, val_embeddings)\n",
    "    \n",
    "\n",
    "    top_indices = torch.topk(cosine_similarities, k=top_k+1, dim=1).indices[0].tolist()\n",
    "    hits = [{'corpus_id': index, 'score': cosine_similarities[0, index].item()} for index in top_indices]\n",
    "    \n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: \n",
    "        del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_bi_encoder(hits, answer, top_k=50):\n",
    "    answer_set = set(answer)\n",
    "    bi_enc_counter = -1\n",
    "    bi_enc_map = 0\n",
    "    tmp_hits = 0\n",
    "    bi_enc_hit_list = [0] * top_k\n",
    "    bi_enc_hit_recall_list = [0] * top_k\n",
    "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    for idx, hit in enumerate(hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer_set:\n",
    "            if bi_enc_counter == -1:\n",
    "                bi_enc_counter = idx + 1\n",
    "            bi_enc_hit_list[idx] = 1\n",
    "            bi_enc_hit_recall_list[idx] = 1\n",
    "            tmp_hits += 1\n",
    "            bi_enc_map += tmp_hits / (idx + 1)\n",
    "            answer_set.remove(candidate)\n",
    "\n",
    "    bi_enc_map /= len(answer)\n",
    "    bi_enc_mrr = 1 / bi_enc_counter if bi_enc_counter != -1 else 0.0\n",
    "\n",
    "    return bi_enc_map, bi_enc_mrr, bi_enc_hit_list, bi_enc_hit_recall_list\n",
    "\n",
    "def evaluate_cr_encoder(hits, answer, top_k=50, mode='cross_score'):\n",
    "    answer_set = set(answer)\n",
    "    cr_enc_counter = -1\n",
    "    cr_enc_map = 0\n",
    "    tmp_hits = 0\n",
    "    cr_enc_hit_list = [0] * top_k\n",
    "    cr_enc_hit_recall_list = [0] * top_k\n",
    "    hits = sorted(hits, key=lambda x: x[mode], reverse=True)\n",
    "    \n",
    "    for idx, hit in enumerate(hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer_set:\n",
    "            if cr_enc_counter == -1:\n",
    "                cr_enc_counter = idx + 1\n",
    "            cr_enc_hit_list[idx] = 1\n",
    "            cr_enc_hit_recall_list[idx] = 1\n",
    "            tmp_hits += 1\n",
    "            cr_enc_map += tmp_hits / (idx + 1)\n",
    "            answer_set.remove(candidate)\n",
    "\n",
    "    cr_enc_map /= len(answer)\n",
    "    cr_enc_mrr = 1 / cr_enc_counter if cr_enc_counter != -1 else 0.0\n",
    "\n",
    "    return cr_enc_map, cr_enc_mrr, cr_enc_hit_list, cr_enc_hit_recall_list\n",
    "\n",
    "bm25_scores = {'mrr': 0, 'map': 0}\n",
    "bi_enc_scores = {'mrr': 0, 'map': 0, 'precision': [0] * 4, 'recall': [0] * 4}\n",
    "cr_enc_scores = {'mrr': 0, 'map': 0, 'precision': [0] * 4, 'recall': [0] * 4}\n",
    "\n",
    "for query_key, answers in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    query = val_corpus[query_key]\n",
    "    \n",
    "    # Fetch precomputed embedding\n",
    "    query_id = title_to_id[query]\n",
    "    precomputed_query_embedding = torch.tensor(embeddings_dict.get(str(query_id)))\n",
    "    hits = forward_pass_rerank(query, precomputed_embedding=precomputed_query_embedding, val_embeddings=val_emb, top_k=top_k)\n",
    "\n",
    "    \n",
    "    \n",
    "    bm25_map, bm25_mrr = evaluate_bm25(query, answers, top_k)\n",
    "    b_map, b_mrr, b_hit, b_rec = evaluate_bi_encoder(hits, answers)\n",
    "    c_map, c_mrr, c_hit, c_rec = evaluate_cr_encoder(hits, answers)\n",
    "    \n",
    "    tmp_precision = [0] * 4\n",
    "    tmp_recall = [0] * 4\n",
    "    for idx, n in enumerate([1, 3, 5, 10]):\n",
    "        tmp_precision[idx] = sum(b_hit[:n]) / n\n",
    "        tmp_recall[idx] = sum(b_rec[:n]) / len(answers)\n",
    "\n",
    "    bi_enc_scores['precision'] = [x + y for (x, y) in zip(bi_enc_scores['precision'], tmp_precision)] \n",
    "    bi_enc_scores['recall'] = [x + y for (x, y) in zip(bi_enc_scores['recall'], tmp_recall)]\n",
    "\n",
    "    tmp_precision = [0] * 4\n",
    "    tmp_recall = [0] * 4\n",
    "    for idx, n in enumerate([1, 3, 5, 10]):\n",
    "        tmp_precision[idx] = sum(c_hit[:n]) / n\n",
    "        tmp_recall[idx] = sum(c_rec[:n]) / len(answers)\n",
    "\n",
    "    cr_enc_scores['precision'] = [x + y for (x, y) in zip(cr_enc_scores['precision'], tmp_precision)] \n",
    "    cr_enc_scores['recall'] = [x + y for (x, y) in zip(cr_enc_scores['recall'], tmp_recall)]\n",
    "\n",
    "    bm25_scores['map'] += bm25_map\n",
    "    bm25_scores['mrr'] += bm25_mrr\n",
    "\n",
    "    bi_enc_scores['map'] += b_map\n",
    "    bi_enc_scores['mrr'] += b_mrr\n",
    "\n",
    "    cr_enc_scores['map'] += c_map\n",
    "    cr_enc_scores['mrr'] += c_mrr\n",
    "\n",
    "bm25_scores['map'] /= len(val_query_answer)\n",
    "bm25_scores['mrr'] /= len(val_query_answer)\n",
    "bi_enc_scores['map'] /= len(val_query_answer)\n",
    "bi_enc_scores['mrr'] /= len(val_query_answer)\n",
    "bi_enc_scores['precision'] = [x/len(val_query_answer) for x in bi_enc_scores['precision']]\n",
    "bi_enc_scores['recall'] = [x/len(val_query_answer) for x in bi_enc_scores['recall']]\n",
    "cr_enc_scores['map'] /= len(val_query_answer)\n",
    "cr_enc_scores['mrr'] /= len(val_query_answer)\n",
    "cr_enc_scores['precision'] = [x/len(val_query_answer) for x in cr_enc_scores['precision']]\n",
    "cr_enc_scores['recall'] = [x/len(val_query_answer) for x in cr_enc_scores['recall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BM25:\\n{json.dumps(bm25_scores, indent=2)}')\n",
    "print(f'Bi-Encoder:\\n{json.dumps(bi_enc_scores, indent=2)}')\n",
    "print(f'Cross-Encoder:\\n{json.dumps(cr_enc_scores, indent=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

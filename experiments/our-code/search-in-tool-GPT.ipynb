{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ahmedalsayed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util, models\n",
    "from sklearn.feature_extraction import _stop_words as stop_words\n",
    "from tqdm.notebook import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import torch\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_enc_weights = '../models/bienc-exp7/'\n",
    "cr_enc_weights = '../models/crenc-exp7/'\n",
    "data_folder = 'generated5'\n",
    "top_k = 50\n",
    "use_base = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Link</th>\n",
       "      <th>Question Title</th>\n",
       "      <th>Question Body</th>\n",
       "      <th>Accepted Answer Body</th>\n",
       "      <th>link</th>\n",
       "      <th>readme</th>\n",
       "      <th>docker</th>\n",
       "      <th>readme_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390150</td>\n",
       "      <td>Authenticating against Active Directory with J...</td>\n",
       "      <td>&lt;p&gt;I have a simple task of authenticating agai...</td>\n",
       "      <td>&lt;p&gt;Here's the code I put together based on exa...</td>\n",
       "      <td>https://github.com/jenkinsci/active-directory-...</td>\n",
       "      <td>Active Directory plugin for Jenkins\\n=========...</td>\n",
       "      <td>Dockerfile from src/test/resources/fixture/Doc...</td>\n",
       "      <td>Active Directory plugin for Jenkins ==========...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1197678</td>\n",
       "      <td>Using Thrift with Delphi Win32</td>\n",
       "      <td>&lt;p&gt;I'm interested in connecting to the Evernot...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Old Answer Replaced thanks to Leo:&lt;...</td>\n",
       "      <td>https://github.com/apache/thrift</td>\n",
       "      <td>Apache Thrift\\n=============\\nIntroduction\\n==...</td>\n",
       "      <td>Dockerfile from build/docker/msvc2017/Dockerfi...</td>\n",
       "      <td>Apache Thrift ============= Introduction =====...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question Link                                     Question Title  \\\n",
       "0         390150  Authenticating against Active Directory with J...   \n",
       "1        1197678                     Using Thrift with Delphi Win32   \n",
       "\n",
       "                                       Question Body  \\\n",
       "0  <p>I have a simple task of authenticating agai...   \n",
       "1  <p>I'm interested in connecting to the Evernot...   \n",
       "\n",
       "                                Accepted Answer Body  \\\n",
       "0  <p>Here's the code I put together based on exa...   \n",
       "1  <p><strong>Old Answer Replaced thanks to Leo:<...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://github.com/jenkinsci/active-directory-...   \n",
       "1                   https://github.com/apache/thrift   \n",
       "\n",
       "                                              readme  \\\n",
       "0  Active Directory plugin for Jenkins\\n=========...   \n",
       "1  Apache Thrift\\n=============\\nIntroduction\\n==...   \n",
       "\n",
       "                                              docker  \\\n",
       "0  Dockerfile from src/test/resources/fixture/Doc...   \n",
       "1  Dockerfile from build/docker/msvc2017/Dockerfi...   \n",
       "\n",
       "                                        readme_short  \n",
       "0  Active Directory plugin for Jenkins ==========...  \n",
       "1  Apache Thrift ============= Introduction =====...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/20231004_data.xlsx', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "  tokenized_doc = []\n",
    "  for token in text.lower().split():\n",
    "    token = token.strip(string.punctuation)\n",
    "\n",
    "    if len(token) > 0 and token not in english_stopwords:\n",
    "      tokenized_doc.append(token)\n",
    "      \n",
    "  return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_base:\n",
    "    word_embedding_model = models.Transformer('distilroberta-base', max_seq_length=350)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    cr_encoder = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6')\n",
    "else:\n",
    "    bi_encoder = SentenceTransformer(bi_enc_weights)\n",
    "    cr_encoder = CrossEncoder(cr_enc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Documents/final-code-microservice-paper/experiments/test_passage_100.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open('/Users/Documents/final-code-microservice-paper/experiments/test_corpus_100.json', 'r') as f:  # Note the _100 in the filename\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "val_query_answer = {}\n",
    "for idx, rel in val_passage.items():\n",
    "    query = val_corpus.get(idx)  \n",
    "    if query:  \n",
    "       \n",
    "        answers = [val_corpus[str(p)] for p in rel if str(p) in val_corpus]\n",
    "        if answers:  \n",
    "            val_query_answer[query] = answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def shorten(text):\n",
    "    tmp = text.split()[:512]\n",
    "    return ' '.join(tmp)\n",
    "\n",
    "val_text = list(val_corpus.values())\n",
    "\n",
    "\n",
    "with open(\"/Users/Documents/final-code-microservice-paper/experiments/data/embeddings_GPT.json\", \"r\") as jsonfile:\n",
    "    embeddings_dict = json.load(jsonfile)\n",
    "\n",
    "val_emb_tensors = []\n",
    "\n",
    "\n",
    "title_to_id = dict(zip(df['Question Title'], df.index))\n",
    "\n",
    "\n",
    "for text in val_text:\n",
    "   \n",
    "    text_id = title_to_id[text]\n",
    "    embedding = embeddings_dict.get(str(text_id))  \n",
    "    if embedding:  \n",
    "        val_emb_tensors.append(torch.tensor(embedding))\n",
    "\n",
    "\n",
    "val_emb = torch.stack(val_emb_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 262307.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tokenized_corpus = []\n",
    "for idx, passage in tqdm(val_corpus.items()):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:31<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Questions Answered Correctly: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Total Questions Answered Correctly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "def compute_cosine_similarity(query_embedding, corpus_embeddings):\n",
    "    # Normalize embeddings\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, keepdim=True)\n",
    "        query_embedding = query_embedding.unsqueeze(0)  # Add an additional dimension\n",
    "    else:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, dim=1, keepdim=True)\n",
    "    \n",
    "    corpus_embeddings = corpus_embeddings / torch.norm(corpus_embeddings, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_similarities = torch.mm(query_embedding, corpus_embeddings.transpose(0, 1))\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass_rerank(query, precomputed_embedding=None, val_embeddings=None, top_k=50):\n",
    "    \n",
    "    if precomputed_embedding is None:\n",
    "        q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    else:\n",
    "        q_emb = precomputed_embedding\n",
    "\n",
    "    # Ensure the query embedding is 2-dimensional\n",
    "    if len(q_emb.shape) == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "\n",
    "    if val_embeddings is None:\n",
    "        raise ValueError(\"No embeddings provided for the validation set.\")\n",
    "    \n",
    "    \n",
    "    if val_embeddings.shape[1] != q_emb.shape[1]:\n",
    "        val_embeddings = val_embeddings.transpose(0, 1)\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(q_emb, val_embeddings)\n",
    "    \n",
    "\n",
    "    top_indices = torch.topk(cosine_similarities, k=top_k+1, dim=1).indices[0].tolist()\n",
    "    hits = [{'corpus_id': index, 'score': cosine_similarities[0, index].item()} for index in top_indices]\n",
    "    \n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: \n",
    "        del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "total_questions_answered_correctly = 0\n",
    "\n",
    "for query, answers_text in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    r = answers_text\n",
    "    query_id = title_to_id[query]\n",
    "    precomputed_query_embedding = torch.tensor(embeddings_dict.get(str(query_id)))\n",
    "    hits = forward_pass_rerank(query, precomputed_embedding=precomputed_query_embedding, val_embeddings=val_emb, top_k=top_k)\n",
    "    \n",
    "    hit_info_list = []\n",
    "    \n",
    "    for hit in hits[:5]:\n",
    "        h_text = val_text[hit['corpus_id']]\n",
    "        cscore_output_cr = cr_encoder.predict([query, h_text])\n",
    "        cscore_cr = cscore_output_cr[0] if isinstance(cscore_output_cr, (list, tuple, np.ndarray)) else cscore_output_cr\n",
    "        hit_info = {\n",
    "            'h_text': h_text,\n",
    "            'cscore': cscore_cr,\n",
    "            'is_correct': \"Yes\" if h_text in r else \"No\"\n",
    "        }\n",
    "        hit_info_list.append(hit_info)\n",
    "    \n",
    "    question_answered_correctly = any(hit_info['is_correct'] == \"Yes\" for hit_info in hit_info_list)\n",
    "    if question_answered_correctly:\n",
    "        total_questions_answered_correctly += 1\n",
    "\n",
    "print(f\"Total Questions Answered Correctly: {total_questions_answered_correctly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:31<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Answers: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Total Correcte Answeres \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "def compute_cosine_similarity(query_embedding, corpus_embeddings):\n",
    "    # Normalize embeddings\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, keepdim=True)\n",
    "        query_embedding = query_embedding.unsqueeze(0)  # Add an additional dimension\n",
    "    else:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, dim=1, keepdim=True)\n",
    "    \n",
    "    corpus_embeddings = corpus_embeddings / torch.norm(corpus_embeddings, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_similarities = torch.mm(query_embedding, corpus_embeddings.transpose(0, 1))\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass_rerank(query, precomputed_embedding=None, val_embeddings=None, top_k=50):\n",
    "    \n",
    "    if precomputed_embedding is None:\n",
    "        q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    else:\n",
    "        q_emb = precomputed_embedding\n",
    "\n",
    "    # Ensure the query embedding is 2-dimensional\n",
    "    if len(q_emb.shape) == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "\n",
    "    if val_embeddings is None:\n",
    "        raise ValueError(\"No embeddings provided for the validation set.\")\n",
    "    \n",
    "    \n",
    "    if val_embeddings.shape[1] != q_emb.shape[1]:\n",
    "        val_embeddings = val_embeddings.transpose(0, 1)\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(q_emb, val_embeddings)\n",
    "    \n",
    "\n",
    "    top_indices = torch.topk(cosine_similarities, k=top_k+1, dim=1).indices[0].tolist()\n",
    "    hits = [{'corpus_id': index, 'score': cosine_similarities[0, index].item()} for index in top_indices]\n",
    "    \n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: \n",
    "        del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for query, answers_text in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    r = answers_text\n",
    "    # The rest of the loop remains the same\n",
    "\n",
    "    #r = val_query_answer[query_key]\n",
    "    # Fetch precomputed embedding\n",
    "    query_id = title_to_id[query]\n",
    "    precomputed_query_embedding = torch.tensor(embeddings_dict.get(str(query_id)))\n",
    "    hits = forward_pass_rerank(query, precomputed_embedding=precomputed_query_embedding, val_embeddings=val_emb, top_k=top_k)\n",
    "    \n",
    "    hit_info_list = []\n",
    "    \n",
    "    for hit in hits[:5]:\n",
    "        h_text = val_text[hit['corpus_id']]\n",
    "        cscore_output_cr = cr_encoder.predict([query, h_text])\n",
    "        cscore_cr = cscore_output_cr[0] if isinstance(cscore_output_cr, (list, tuple, np.ndarray)) else cscore_output_cr\n",
    "        hit_info = {\n",
    "            'h_text': h_text,\n",
    "            'cscore': cscore_cr,\n",
    "            'is_correct': \"Yes\" if h_text in r else \"No\"\n",
    "        }\n",
    "        hit_info_list.append(hit_info)\n",
    "    \n",
    "    correct_count = sum(1 for hit_info in hit_info_list if hit_info['is_correct'] == \"Yes\")\n",
    "    total_correct += correct_count\n",
    "\n",
    "print(f\"Total Correct Answers: {total_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 9/85 [00:03<00:29,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Alternative to Kubernetes rolling update in rest api\n",
      "\tHit: Are Kubernetes API calls secret update and configmap update atomic calls? - Correct: No\n",
      "\tHit: Kubernetes Watch Pod Events with api - Correct: Yes\n",
      "\tHit: Restricted Kubernetes dashboard? - Correct: No\n",
      "\tHit: Running dashboard inside play-with-kubernetes - Correct: No\n",
      "\tHit: Kubernetes Storage on bare-metal/private cloud - Correct: Yes\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 12/85 [00:04<00:26,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Authentication views for Laravel 5.1\n",
      "\tHit: Force logout of specific user by user id in Laravel - Correct: Yes\n",
      "\tHit: Best way to make restfull API in Laravel - Correct: Yes\n",
      "\tHit: Kubernetes simple authentication - Correct: No\n",
      "\tHit: Create user with LDAP authentification in airflow 2.1.4 - Correct: No\n",
      "\tHit: React Native Phone-based login - Correct: No\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 69/85 [00:26<00:06,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Giving a docker container a routable ip address\n",
      "\tHit: Assigning IP address to docker containers? - Correct: Yes\n",
      "\tHit: Bind to multiple ip addresses in a single docker container - Correct: Yes\n",
      "\tHit: Run Jupyter Notebook in the Background on Docker - Correct: No\n",
      "\tHit: Start kubernetes container with specific command - Correct: No\n",
      "\tHit: Project layout with vagrant, docker and git - Correct: No\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:33<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Answers: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print the question where more than 2 hits are correct :\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "def compute_cosine_similarity(query_embedding, corpus_embeddings):\n",
    "    # Normalize embeddings\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, keepdim=True)\n",
    "        query_embedding = query_embedding.unsqueeze(0)  # Add an additional dimension\n",
    "    else:\n",
    "        query_embedding = query_embedding / torch.norm(query_embedding, dim=1, keepdim=True)\n",
    "    \n",
    "    corpus_embeddings = corpus_embeddings / torch.norm(corpus_embeddings, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_similarities = torch.mm(query_embedding, corpus_embeddings.transpose(0, 1))\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass_rerank(query, precomputed_embedding=None, val_embeddings=None, top_k=50):\n",
    "    \n",
    "    if precomputed_embedding is None:\n",
    "        q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    else:\n",
    "        q_emb = precomputed_embedding\n",
    "\n",
    "    # Ensure the query embedding is 2-dimensional\n",
    "    if len(q_emb.shape) == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "\n",
    "    if val_embeddings is None:\n",
    "        raise ValueError(\"No embeddings provided for the validation set.\")\n",
    "    \n",
    "    \n",
    "    if val_embeddings.shape[1] != q_emb.shape[1]:\n",
    "        val_embeddings = val_embeddings.transpose(0, 1)\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(q_emb, val_embeddings)\n",
    "    \n",
    "\n",
    "    top_indices = torch.topk(cosine_similarities, k=top_k+1, dim=1).indices[0].tolist()\n",
    "    hits = [{'corpus_id': index, 'score': cosine_similarities[0, index].item()} for index in top_indices]\n",
    "    \n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: \n",
    "        del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for query, answers_text in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    r = answers_text\n",
    "\n",
    "    # Fetch precomputed embedding\n",
    "    query_id = title_to_id[query]\n",
    "    precomputed_query_embedding = torch.tensor(embeddings_dict.get(str(query_id)))\n",
    "    hits = forward_pass_rerank(query, precomputed_embedding=precomputed_query_embedding, val_embeddings=val_emb, top_k=top_k)\n",
    "    \n",
    "    hit_info_list = []\n",
    "    \n",
    "    for hit in hits[:5]:\n",
    "        h_text = val_text[hit['corpus_id']]\n",
    "        cscore_output_cr = cr_encoder.predict([query, h_text])\n",
    "        cscore_cr = cscore_output_cr[0] if isinstance(cscore_output_cr, (list, tuple, np.ndarray)) else cscore_output_cr\n",
    "        hit_info = {\n",
    "            'h_text': h_text,\n",
    "            'cscore': cscore_cr,\n",
    "            'is_correct': \"Yes\" if h_text in r else \"No\"\n",
    "        }\n",
    "        hit_info_list.append(hit_info)\n",
    "    \n",
    "    correct_count = sum(1 for hit_info in hit_info_list if hit_info['is_correct'] == \"Yes\")\n",
    "    \n",
    "    # Check if more than 2 hits are correct, and if so, print the question and its hits\n",
    "    if correct_count >= 2:\n",
    "        print(f\"Question: {query}\")\n",
    "        for hit_info in hit_info_list:\n",
    "            print(f\"\\tHit: {hit_info['h_text']} - Correct: {hit_info['is_correct']}\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    total_correct += correct_count\n",
    "\n",
    "print(f\"Total Correct Answers: {total_correct}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

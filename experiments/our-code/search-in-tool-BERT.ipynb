{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util, models\n",
    "from sklearn.feature_extraction import _stop_words as stop_words\n",
    "from tqdm.notebook import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import torch\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_enc_weights = '../models/bienc-exp7/'\n",
    "cr_enc_weights = '../models/crenc-exp7/'\n",
    "data_folder = 'generated5'\n",
    "top_k = 50\n",
    "use_base = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/20231004_data.xlsx', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "  tokenized_doc = []\n",
    "  for token in text.lower().split():\n",
    "    token = token.strip(string.punctuation)\n",
    "\n",
    "    if len(token) > 0 and token not in english_stopwords:\n",
    "      tokenized_doc.append(token)\n",
    "      \n",
    "  return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_base:\n",
    "    word_embedding_model = models.Transformer('distilroberta-base', max_seq_length=350)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    cr_encoder = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6')\n",
    "else:\n",
    "    bi_encoder = SentenceTransformer(bi_enc_weights)\n",
    "    cr_encoder = CrossEncoder(cr_enc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Documents/final-code-microservice-paper/experiments/test_passage_100.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open('/Users/Documents/final-code-microservice-paper/experiments/test_corpus_100.json', 'r') as f:  # Note the _100 in the filename\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "val_query_answer = {}\n",
    "for idx, rel in val_passage.items():\n",
    "    query = val_corpus.get(idx)  \n",
    "    if query:  \n",
    "        \n",
    "        answers = [val_corpus[str(p)] for p in rel if str(p) in val_corpus]\n",
    "        if answers:  \n",
    "            val_query_answer[query] = answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text = list(val_corpus.values())\n",
    "val_emb = bi_encoder.encode(val_text, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tokenized_corpus = []\n",
    "for idx, passage in tqdm(val_corpus.items()):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Total Correcte Answeres\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "def forward_pass_rerank(query, top_k=50):\n",
    "    q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search([q_emb], val_emb, top_k=top_k+1)[0]\n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "total_correct = 0  \n",
    "\n",
    "for (query_key, answers) in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    q = query_key\n",
    "    r = val_query_answer[query_key]\n",
    "    hits = forward_pass_rerank(q)\n",
    "    \n",
    "    hit_info_list = []\n",
    "    \n",
    "    for hit in hits[:5]:\n",
    "        h_text = val_text[hit['corpus_id']]\n",
    "        hit_info = {\n",
    "            'h_text': h_text,\n",
    "            'is_correct': \"Yes\" if h_text in r else \"No\"\n",
    "        }\n",
    "        hit_info_list.append(hit_info)\n",
    "\n",
    "    correct_count = 0\n",
    "    \n",
    "    for hit_info in hit_info_list:\n",
    "        is_correct = hit_info['is_correct']\n",
    "        \n",
    "        if is_correct == \"Yes\":\n",
    "            correct_count += 1\n",
    "    \n",
    "    total_correct += correct_count\n",
    "\n",
    "print(f\"Total correct answers: {total_correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Questions Answered Correctly\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive class found in y_true, recall is set to one for all thresholds.\")\n",
    "\n",
    "def forward_pass_rerank(query, top_k=50):\n",
    "    q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search([q_emb], val_emb, top_k=top_k+1)[0]\n",
    "\n",
    "    cross_inputs = []\n",
    "    \n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "        \n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "    \n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "        \n",
    "    if to_remove != -1: del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "total_questions_answered_correctly = 0  \n",
    "\n",
    "for (query_key, answers) in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    q = query_key\n",
    "    r = val_query_answer[query_key]\n",
    "    hits = forward_pass_rerank(q)\n",
    "    \n",
    "    hit_info_list = []\n",
    "    \n",
    "    for hit in hits[:5]:\n",
    "        h_text = val_text[hit['corpus_id']]\n",
    "        hit_info = {\n",
    "            'h_text': h_text,\n",
    "            'is_correct': \"Yes\" if h_text in r else \"No\"\n",
    "        }\n",
    "        hit_info_list.append(hit_info)\n",
    "\n",
    "    question_answered_correctly = any(hit_info['is_correct'] == \"Yes\" for hit_info in hit_info_list)\n",
    "    \n",
    "    if question_answered_correctly:\n",
    "        total_questions_answered_correctly += 1\n",
    "\n",
    "print(f\"Total Questions Answered Correctly: {total_questions_answered_correctly}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

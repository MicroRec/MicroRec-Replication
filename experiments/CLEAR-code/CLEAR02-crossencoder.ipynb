{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util, models, evaluation, losses, InputExample\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-6'\n",
    "model_save_path = 'models/crenc-exp7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(Passage_dict):\n",
    "    triplets = []\n",
    "    for k, v in Passage_dict.items():\n",
    "        for x in v[0]:\n",
    "            for y in v[1]:\n",
    "                triplets.append([k, x, y])\n",
    "\n",
    "    return triplets\n",
    "\n",
    "def get_dataset(triplets, corpus):\n",
    "    dataset = []        \n",
    "    for triplet in triplets:\n",
    "        qid, pos_id, neg_id = triplet\n",
    "        \n",
    "        qid = str(qid)\n",
    "        pos_id = str(pos_id)\n",
    "        neg_id = str(neg_id)\n",
    "\n",
    "        query_text = corpus[qid]\n",
    "        pos_text = corpus[pos_id]\n",
    "        neg_text = corpus[neg_id]\n",
    "\n",
    "        pos_instance = InputExample(texts=[query_text, pos_text],label=1)\n",
    "        neg_instance = InputExample(texts=[query_text, neg_text],label=0)\n",
    "\n",
    "        dataset.append(pos_instance)\n",
    "        dataset.append(neg_instance)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "with open('./data/generated4/train_passage.json', 'r') as f:\n",
    "    train_passage = json.load(f)\n",
    "\n",
    "with open('./data/generated4/train_corpus.json', 'r') as f:\n",
    "    train_corpus = json.load(f)\n",
    "\n",
    "with open('./data/generated4/val_passage.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open('./data/generated4/val_corpus.json', 'r') as f:\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "train_triplets = get_triplets(train_passage)\n",
    "train_dataset = get_dataset(train_triplets, train_corpus)\n",
    "\n",
    "val_triplets = get_triplets(val_passage)\n",
    "val_dataset = get_dataset(val_triplets, val_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='- %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()]\n",
    ")\n",
    "\n",
    "model = CrossEncoder(model_name)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CEBinaryClassificationEvaluator.from_input_examples(val_dataset, name='cross_encoder_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = int(len(train_dataloader) * 5 * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    epochs=10,\n",
    "    evaluation_steps=int(len(train_dataloader) / 2),\n",
    "    warmup_steps=warmup_steps,\n",
    "    save_best_model=True,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder('./models/crenc-exp1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "negatives = []\n",
    "\n",
    "for triplet in val_triplets:\n",
    "    query = val_corpus[triplet[0]]\n",
    "    pos = val_corpus[str(triplet[1])]\n",
    "    neg = val_corpus[str(triplet[2])]\n",
    "\n",
    "    positives.append([query, pos])\n",
    "    negatives.append([query, neg])\n",
    "\n",
    "positive_scores = model.predict(positives)\n",
    "negative_scores = model.predict(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_out = np.where(positive_scores < 0.5)[0]\n",
    "negative_out = np.where(negative_scores >= 0.5)[0]\n",
    "\n",
    "# sample some bad positive samples\n",
    "for idx in np.random.choice(positive_out, 10, replace=False):\n",
    "    score = positive_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some bad negative samples\n",
    "for idx in np.random.choice(negative_out, 10, replace=False):\n",
    "    score = negative_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][2])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_good = np.where(positive_scores > 0.8)[0]\n",
    "negative_good = np.where(negative_scores < 0.2)[0]\n",
    "\n",
    "# sample some good positive samples\n",
    "for idx in np.random.choice(positive_good, 10, replace=False):\n",
    "    score = positive_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some good negative samples\n",
    "for idx in np.random.choice(negative_good, 10, replace=False):\n",
    "    score = negative_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

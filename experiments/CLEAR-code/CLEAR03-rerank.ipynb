{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util, models\n",
    "from sklearn.feature_extraction import _stop_words as stop_words\n",
    "from tqdm.notebook import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import torch\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_enc_weights = './models/bienc-exp7/'\n",
    "cr_enc_weights = './models/crenc-exp7/'\n",
    "data_folder = 'generated5'\n",
    "top_k = 50\n",
    "use_base = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f'./data/{data_folder}/dataset.json')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "  tokenized_doc = []\n",
    "  for token in text.lower().split():\n",
    "    token = token.strip(string.punctuation)\n",
    "\n",
    "    if len(token) > 0 and token not in english_stopwords:\n",
    "      tokenized_doc.append(token)\n",
    "      \n",
    "  return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_base:\n",
    "    word_embedding_model = models.Transformer('distilroberta-base', max_seq_length=350)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    cr_encoder = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6')\n",
    "else:\n",
    "    bi_encoder = SentenceTransformer(bi_enc_weights)\n",
    "    cr_encoder = CrossEncoder(cr_enc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{data_folder}/test_passage.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open(f'./data/{data_folder}/test_corpus.json', 'r') as f:\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "val_query_answer = {}\n",
    "for idx, rel in val_passage.items():\n",
    "    query = val_corpus[idx]\n",
    "    pos = rel[0]\n",
    "    answers = [val_corpus[str(p)] for p in pos]\n",
    "    val_query_answer[idx] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text = list(val_corpus.values())\n",
    "val_emb = bi_encoder.encode(val_text, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tokenized_corpus = []\n",
    "for idx, passage in tqdm(val_corpus.items()):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to evaluate a single sample\n",
    "\n",
    "def evaluate_bm25(query, answer, top_k=50):\n",
    "    # find the top 50 similar questions from the corpus based on bm25_scores\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -top_k)[-top_k:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    bm25_counter = -1\n",
    "    bm25_map = 0\n",
    "    bm25_mrr = 0\n",
    "    tmp_hits = 0\n",
    "    answer2 = answer[:]\n",
    "    for idx, hit in enumerate(bm25_hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer:\n",
    "            if bm25_counter == -1:\n",
    "                bm25_counter = idx + 1\n",
    "\n",
    "            tmp_hits += 1\n",
    "            bm25_map += tmp_hits / (idx + 1)\n",
    "            answer2.remove(candidate)\n",
    "\n",
    "    bm25_map /= len(answer)\n",
    "    if bm25_counter == -1:\n",
    "        bm25_mrr = 0.0\n",
    "    else:\n",
    "        bm25_mrr = 1 / bm25_counter\n",
    "\n",
    "    return bm25_map, bm25_mrr\n",
    "        \n",
    "def forward_pass(query, top_k=50):\n",
    "    q_emb = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search([q_emb], val_emb, top_k=top_k+1)[0]\n",
    "\n",
    "    cross_inputs = []\n",
    "    to_remove = -1\n",
    "    for hit in hits:\n",
    "        # idx = val_idx[hit['corpus_id']]\n",
    "        text = val_text[hit['corpus_id']]\n",
    "        if query == text:\n",
    "            to_remove = hits.index(hit)\n",
    "        cross_inputs.append([query, text])\n",
    "    cross_scores = cr_encoder.predict(cross_inputs)\n",
    "\n",
    "    for idx in range(len(cross_scores)):\n",
    "        hits[idx]['cross_score'] = cross_scores[idx]\n",
    "\n",
    "    if to_remove != -1: del hits[to_remove]\n",
    "    hits = hits[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "def evaluate_bi_encoder(hits, answer, top_k=50):\n",
    "    bi_enc_counter = -1\n",
    "    bi_enc_map = 0\n",
    "    bi_enc_mrr = 0\n",
    "    tmp_hits = 0\n",
    "    bi_enc_hit_list = [0] * top_k\n",
    "    bi_enc_hit_recall_list = [0] * top_k\n",
    "    answer2 = answer[:]\n",
    "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "    for idx, hit in enumerate(hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer2:\n",
    "            if bi_enc_counter == -1: bi_enc_counter = idx + 1\n",
    "            bi_enc_hit_list[idx] = 1\n",
    "            bi_enc_hit_recall_list[idx] = 1\n",
    "            tmp_hits += 1\n",
    "            bi_enc_map += tmp_hits / (idx + 1)\n",
    "            answer2.remove(candidate)\n",
    "    \n",
    "    bi_enc_map /= len(answer)\n",
    "    if bi_enc_counter == -1:\n",
    "        bi_enc_mrr = 0.0\n",
    "    else:\n",
    "        bi_enc_mrr = 1 / bi_enc_counter\n",
    "\n",
    "    return bi_enc_map, bi_enc_mrr, bi_enc_hit_list, bi_enc_hit_recall_list\n",
    "\n",
    "def evalaute_cr_encoder(hits, answer, top_k=50):\n",
    "    cr_enc_counter = -1\n",
    "    cr_enc_map = 0\n",
    "    cr_enc_mrr = 0\n",
    "    tmp_hits = 0\n",
    "    cr_enc_hit_list = [0] * top_k\n",
    "    cr_enc_hit_recall_list = [0] * top_k\n",
    "    answer2 = answer[:]\n",
    "    hits = sorted(hits, key=lambda x: x['cross_score'], reverse=True)\n",
    "    for idx, hit in enumerate(hits):\n",
    "        candidate = val_text[hit['corpus_id']]\n",
    "        if candidate in answer2:\n",
    "            if cr_enc_counter == -1: cr_enc_counter = idx + 1\n",
    "            cr_enc_hit_list[idx] = 1\n",
    "            cr_enc_hit_recall_list[idx] = 1\n",
    "            tmp_hits += 1\n",
    "            cr_enc_map += tmp_hits / (idx + 1)\n",
    "            answer2.remove(candidate)\n",
    "\n",
    "    cr_enc_map /= len(answer)\n",
    "    if cr_enc_counter == -1:\n",
    "        cr_enc_mrr = 0.0\n",
    "    else:\n",
    "        cr_enc_mrr = 1 / cr_enc_counter\n",
    "\n",
    "    return cr_enc_map, cr_enc_mrr, cr_enc_hit_list, cr_enc_hit_recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df[df['Question Title'] == q]['answer'])\n",
    "#print(df[df['Question Title'] == 'Handle redis cache availability with spring boot']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 1 sample\n",
    "\n",
    "q = val_corpus['2281']\n",
    "a = val_query_answer['2281']\n",
    "hits = forward_pass(q)\n",
    "b_map, b_mrr, _, _ = evaluate_bi_encoder(hits, a)\n",
    "c_map, c_mrr, _, _ = evalaute_cr_encoder(hits, a)\n",
    "\n",
    "\n",
    "# further checks\n",
    "print(q)\n",
    "print('Hits:')\n",
    "for hit in hits[:5]:\n",
    "    h_text = val_text[hit['corpus_id']]\n",
    "    cos_sim = util.pytorch_cos_sim(\n",
    "        bi_encoder.encode(q, convert_to_tensor=True), bi_encoder.encode(h_text, convert_to_tensor=True)\n",
    "    )[0][0].cpu().numpy()\n",
    "    cscore = cr_encoder.predict([q, h_text])\n",
    "    print(f'{h_text}\\nCos sim: Check: {cos_sim:.3f} Predicted: {hit[\"score\"]:.3f}')\n",
    "    print(f'Cross Encoder:\\nCheck: {cscore:.3f} Predicted: {hit[\"cross_score\"]:.3f}')\n",
    "    print()\n",
    "\n",
    "print('Answers:')\n",
    "data_id = df[df['Question Title'] == q]['index'].values[0]\n",
    "print(data_id)\n",
    "answers = val_query_answer[str(data_id)]\n",
    "for answer in answers[:5]:\n",
    "    cos_sim = util.pytorch_cos_sim(\n",
    "        bi_encoder.encode(q, convert_to_tensor=True), bi_encoder.encode(answer, convert_to_tensor=True)\n",
    "    )[0][0].cpu().numpy()\n",
    "    cscore = cr_encoder.predict([q, answer])\n",
    "    print(f'{answer}\\nCos sim: {cos_sim:.3f}')\n",
    "    print(f'Cross Encoder:\\nCheck: {cscore:.3f}')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = {'mrr': 0, 'map': 0}\n",
    "bi_enc_scores = {'mrr': 0, 'map': 0, 'precision': [0] * 4, 'recall': [0] * 4}\n",
    "cr_enc_scores = {'mrr': 0, 'map': 0, 'precision': [0] * 4, 'recall': [0] * 4}\n",
    "\n",
    "for query_key, answers in tqdm(val_query_answer.items(), total=len(val_query_answer)):\n",
    "    query= val_corpus[query_key]\n",
    "    hits = forward_pass(query, top_k)\n",
    "    bm25_map, bm25_mrr = evaluate_bm25(query, answers, top_k)\n",
    "    b_map, b_mrr, b_hit, b_rec = evaluate_bi_encoder(hits, answers)\n",
    "    c_map, c_mrr, c_hit, c_rec = evalaute_cr_encoder(hits, answers)\n",
    "    \n",
    "    tmp_precision = [0] * 4\n",
    "    tmp_recall = [0] * 4\n",
    "    for idx, n in enumerate([1, 3, 5, 10]):\n",
    "        tmp_precision[idx] = sum(b_hit[:n]) / n\n",
    "        tmp_recall[idx] = sum(b_rec[:n]) / len(answers)\n",
    "\n",
    "    bi_enc_scores['precision'] = [x + y for (x, y) in zip(bi_enc_scores['precision'], tmp_precision)] \n",
    "    bi_enc_scores['recall'] = [x + y for (x, y) in zip(bi_enc_scores['recall'], tmp_recall)]\n",
    "\n",
    "    tmp_precision = [0] * 4\n",
    "    tmp_recall = [0] * 4\n",
    "    for idx, n in enumerate([1, 3, 5, 10]):\n",
    "        tmp_precision[idx] = sum(c_hit[:n]) / n\n",
    "        tmp_recall[idx] = sum(c_rec[:n]) / len(answers)\n",
    "\n",
    "    cr_enc_scores['precision'] = [x + y for (x, y) in zip(cr_enc_scores['precision'], tmp_precision)] \n",
    "    cr_enc_scores['recall'] = [x + y for (x, y) in zip(cr_enc_scores['recall'], tmp_recall)]\n",
    "\n",
    "    bm25_scores['map'] += bm25_map\n",
    "    bm25_scores['mrr'] += bm25_mrr\n",
    "\n",
    "    bi_enc_scores['map'] += b_map\n",
    "    bi_enc_scores['mrr'] += b_mrr\n",
    "\n",
    "    cr_enc_scores['map'] += c_map\n",
    "    cr_enc_scores['mrr'] += c_mrr\n",
    "\n",
    "bm25_scores['map'] /= len(val_query_answer)\n",
    "bm25_scores['mrr'] /= len(val_query_answer)\n",
    "bi_enc_scores['map'] /= len(val_query_answer)\n",
    "bi_enc_scores['mrr'] /= len(val_query_answer)\n",
    "bi_enc_scores['precision'] = [x/len(val_query_answer) for x in bi_enc_scores['precision']]\n",
    "bi_enc_scores['recall'] = [x/len(val_query_answer) for x in bi_enc_scores['recall']]\n",
    "cr_enc_scores['map'] /= len(val_query_answer)\n",
    "cr_enc_scores['mrr'] /= len(val_query_answer)\n",
    "cr_enc_scores['precision'] = [x/len(val_query_answer) for x in cr_enc_scores['precision']]\n",
    "cr_enc_scores['recall'] = [x/len(val_query_answer) for x in cr_enc_scores['recall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BM25:\\n{json.dumps(bm25_scores, indent=2)}')\n",
    "print(f'Bi-Encoder:\\n{json.dumps(bi_enc_scores, indent=2)}')\n",
    "print(f'Cross-Encoder:\\n{json.dumps(cr_enc_scores, indent=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
